{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Install OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/vk2161/.local/lib/python3.8/site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from opencv-python) (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import json #for label processing\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision import models as models\n",
    "from torchvision import models as vision_models\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "lr = 0.00001\n",
    "epochs = 75\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.3605, 0.3185, 0.2916],\n",
    "                                 std=[0.3822, 0.3564, 0.3438])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, train, test):\n",
    "        self.csv = csv\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.all_image_names = self.csv[:]['Id']\n",
    "        labels = self.csv['labels']\n",
    "        \n",
    "        self.all_labels = np.array(([json.loads(y) for y in labels]))\n",
    "        #let train be 0.85 total. then choose .75 of it as train and .25 validation\n",
    "        self.train_ratio = int(0.80 * 0.85 * len(self.csv))\n",
    "        self.valid_ratio = int(0.20 * 0.85 * len(self.csv))\n",
    "        self.test_ratio = int(0.15 * len(self.csv))\n",
    "        \n",
    "        self.text = self.csv[:]['Text']\n",
    "        \n",
    "        # set the training data images and labels\n",
    "        if self.train == True:\n",
    "            print(f\"Number of training images: {self.train_ratio}\")\n",
    "            self.image_names = list(self.all_image_names[:self.train_ratio])\n",
    "            self.labels = list(self.all_labels[:self.train_ratio])\n",
    "            # define the training transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        # set the validation data images and labels\n",
    "        elif self.train == False and self.test == False:\n",
    "            print(f\"Number of validation images: {self.valid_ratio}\")\n",
    "            self.image_names = list(self.all_image_names[self.train_ratio:-self.test_ratio])\n",
    "            self.labels = list(self.all_labels[self.train_ratio:-self.test_ratio])\n",
    "            \n",
    "            # define the validation transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "        # set the test data images and labels, only last 10 images\n",
    "        # this, we will use in a separate inference script\n",
    "        elif self.test == True and self.train == False:\n",
    "            print(f\"Number of testing images: {self.test_ratio}\")\n",
    "            self.image_names = list(self.all_image_names[-self.test_ratio:])\n",
    "            self.labels = list(self.all_labels[-self.test_ratio:])\n",
    "             # define the test transforms\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(f\"/scratch/vk2161/CV/orig_dataset/400posters/{self.image_names[index]}\")\n",
    "        # convert the image from BGR to RGB color format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # apply image transforms\n",
    "        image = self.transform(image)\n",
    "        targets = self.labels[index]\n",
    "\n",
    "        #Tesseract was not able to parse some of the poster so handle null cases\n",
    "        des = \"\" if self.text[index] != self.text[index] else self.text[index]\n",
    "        \n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float32),\n",
    "            'label': torch.tensor(targets, dtype=torch.float32),\n",
    "            'text' : des\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "def resnetmodel(pretrained, requires_grad):\n",
    "    model = models.resnet50(progress=True, pretrained=pretrained)\n",
    "    # to freeze the hidden layers\n",
    "    if requires_grad == False:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    # to train the hidden layers\n",
    "    elif requires_grad == True:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    # make the classification layer learnable\n",
    "    # we have 19 classes in total\n",
    "    model.fc = nn.Linear(2048, 19)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, train_data, device):\n",
    "    print('***** Training *****')\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        counter += 1\n",
    "        data, target = data['image'].to(device), data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_running_loss += loss.item()\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss / counter\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, val_data, device):\n",
    "    print('***** Validating *****')\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            counter += 1\n",
    "            data, target = data['image'].to(device), data['label'].to(device)\n",
    "            outputs = model(data)\n",
    "            # apply sigmoid activation to get all the outputs between 0 and 1\n",
    "            loss = criterion(outputs, target)\n",
    "            val_running_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_running_loss / counter\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cuda\n"
     ]
    }
   ],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "# initialize the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device =\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init train/test/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 28212\n",
      "Number of validation images: 7053\n"
     ]
    }
   ],
   "source": [
    "# read the training csv file\n",
    "train_csv = pd.read_csv('/scratch/vk2161/CV/orig_dataset/modified_ocr.csv')\n",
    "\n",
    "# train dataset\n",
    "train_data = ImageDataset(\n",
    "    train_csv, train=True, test=False\n",
    ")\n",
    "# validation dataset\n",
    "valid_data = ImageDataset(\n",
    "    train_csv, train=False, test=False\n",
    ")\n",
    "# train data loader\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "# validation data loader\n",
    "valid_loader = DataLoader(\n",
    "    valid_data, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Init and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intialize the model\n",
    "model = resnetmodel(pretrained=True, requires_grad=True).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-6, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=lr, max_lr=0.01, step_size_up=1000)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=20)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[7,12,15], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start the training and validation\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n\\nEpoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(\n",
    "        model, train_loader, optimizer, criterion, train_data, device\n",
    "    )\n",
    "    #adaptive learning rate\n",
    "    scheduler.step()\n",
    "    valid_epoch_loss = validate(\n",
    "        model, valid_loader, criterion, valid_data, device\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    print(f\"  Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f'  Val Loss: {valid_epoch_loss:.4f}')\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': criterion,\n",
    "        }, '/scratch/srs9969/output/mode1_16Dec_8515_930am_'+ str(epoch) +'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save the train and validation line graphs\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(valid_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the computation device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#intialize the model\n",
    "# model = models.model(pretrained=False, requires_grad=False).to(device)\n",
    "# load the model checkpoint\n",
    "checkpoint = torch.load('/scratch/srs9969/output/mode1_15Dec_8515_720pm_74.pth')\n",
    "# load model weights state_dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Spacy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en')\n",
    "nlp = spacy.load('en_pytt_bertbaseuncased_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleResnet(nn.Module):\n",
    "    def __init__(self, resnet, spacy, nb_classes=10):\n",
    "        super(EnsembleResnet, self).__init__()\n",
    "        self.resnet = resnet\n",
    "        self.spacy = spacy\n",
    "        # Remove last linear layer\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Create new classifier\n",
    "        # The reason for adding 2048 + 768 is spacy\n",
    "        self.classifier = nn.Linear(2048+768, 19)\n",
    "        \n",
    "    def forward(self, img, txt):\n",
    "        \n",
    "        r = self.resnet(img)\n",
    "        r = r.view(r.size(0), -1)\n",
    "        \n",
    "        s = None\n",
    "        \n",
    "        if len(txt) == 0:\n",
    "            s = np.zeros(768, dtype=float)\n",
    "            s = torch.tensor(s, dtype=torch.float32)            \n",
    "        else:\n",
    "            s = self.spacy(txt).vector\n",
    "            s = torch.tensor(s)\n",
    "            s = s.view(s.size(0), -1)\n",
    "        \n",
    "        s = s.reshape((1,768))\n",
    "        s = s.to(device)\n",
    "        \n",
    "        res = torch.cat((r, s), dim=1)\n",
    "        res = self.classifier(F.relu(res))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = EnsembleResnet(model, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing images: 6223\n"
     ]
    }
   ],
   "source": [
    "# train_csv = pd.read_csv('../input/movie-classifier/Multi_Label_dataset/train.csv')\n",
    "# genres = train_csv.columns.values[1]\n",
    "labels = train_csv['labels']\n",
    "genres = np.array(([json.loads(y) for y in labels]))\n",
    "\n",
    "# prepare the test dataset and dataloader\n",
    "test_data = ImageDataset(\n",
    "    train_csv, train=False, test=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data, \n",
    "    batch_size=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18405406091154564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "h_loss = 0\n",
    "test_size = 0\n",
    "\n",
    "input_matrix = None\n",
    "output_matrix = None\n",
    "\n",
    "for counter, data in enumerate(test_loader):\n",
    "    image, target, text = data['image'].to(device), data['label'], data['text']\n",
    "    # get all the index positions where value == 1\n",
    "    target_indices = [i for i in range(len(target[0])) if target[0][i] == 1]\n",
    "    # get the predictions by passing the image through the model\n",
    "    \n",
    "    txt = \"\"\n",
    "    \n",
    "    if len(text) != 0:\n",
    "        #print(\"Text here\", text)\n",
    "        txt = ''.join(text)\n",
    "    \n",
    "    #print(text)\n",
    "    \n",
    "    input_x = (image, txt)\n",
    "    outputs = ensemble_model(image, txt)\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "   \n",
    "    #outputs = outputs.detach().cpu()\n",
    "    \n",
    "    #we need to get top k result depending on the no of labels our dataset has\n",
    "    target_labels = data['label']\n",
    "    top_k = torch.count_nonzero(target_labels)\n",
    "    \n",
    "    # get the top_k result\n",
    "    result, indices = torch.topk(outputs, k=top_k ,largest=True)\n",
    "    \n",
    "    #flatten the indices\n",
    "    indices = indices.flatten()\n",
    "    #unsqueeze the indices\n",
    "    indices = indices.unsqueeze(0)\n",
    "    \n",
    "    #We have the indices now, now lets create a one-hot encoding tensor\n",
    "    predicted_labels = torch.zeros(indices.size(0), 19).scatter_(1, indices, 1)\n",
    "    \n",
    "    #Calculate the hamming loss\n",
    "    h_loss += hamming_loss(target_labels, predicted_labels)\n",
    "    test_size = test_size + 1 \n",
    "    \n",
    "    input_matrix = target_labels if input_matrix is None else torch.vstack((input_matrix, target_labels))\n",
    "    output_matrix = predicted_labels if output_matrix is None else torch.vstack((output_matrix, predicted_labels))    \n",
    "    \n",
    "print(h_loss/test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "genresList = pd.read_csv('/scratch/srs9969/genre_List.csv')['Genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Animation\n",
       "1           Adventure\n",
       "2              Family\n",
       "3              Comedy\n",
       "4             Fantasy\n",
       "5             Romance\n",
       "6               Drama\n",
       "7              Action\n",
       "8               Crime\n",
       "9            Thriller\n",
       "10             Horror\n",
       "11            History\n",
       "12    Science Fiction\n",
       "13            Mystery\n",
       "14                War\n",
       "15              Music\n",
       "16        Documentary\n",
       "17            Western\n",
       "18           TV Movie\n",
       "Name: Genres, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = input_matrix.detach().cpu().numpy()\n",
    "output_matrix = output_matrix.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# For each class\n",
    "precision = precision_score(input_matrix, output_matrix, average=None)\n",
    "recall = recall_score(input_matrix, output_matrix, average=None)\n",
    "f1_score = f1_score(input_matrix, output_matrix, average=None)\n",
    "h_loss = hamming_loss(input_matrix, output_matrix)\n",
    "\n",
    "#Send this to a Map \n",
    "precision_map = dict()\n",
    "for p, g in zip (precision, genresList):\n",
    "    precision_map[g] = p\n",
    "\n",
    "recall_map = dict()\n",
    "for r, g in zip (recall, genresList):\n",
    "    recall_map[g] = r\n",
    "\n",
    "f1_score_map = dict()\n",
    "for f1, g in zip (f1_score, genresList):\n",
    "    f1_score_map[g] = f1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.17103236 0.04166667 0.5        0.1257485  0.21333333\n",
      " 0.52422145 0.19696084 0.17647059 0.21730068 0.25477707 0.06802721\n",
      " 0.23125    0.07488987 0.04044877 0.02409639 0.028      0.01262626\n",
      " 0.05809524]\n",
      "[8.33333333e-03 2.50000000e-01 6.62251656e-03 5.86854460e-04\n",
      " 6.58307210e-02 2.31368187e-01 1.00564222e-01 3.76957494e-01\n",
      " 3.50584307e-02 3.88630009e-01 5.73888092e-02 8.96860987e-02\n",
      " 2.43956044e-01 1.08280255e-01 7.17277487e-01 7.78210117e-03\n",
      " 8.98587933e-03 3.81679389e-02 3.26203209e-01]\n",
      "[0.01652893 0.2031107  0.01142857 0.00117233 0.08641975 0.22198506\n",
      " 0.16875522 0.25873321 0.05849582 0.27874332 0.09367681 0.07736944\n",
      " 0.23743316 0.08854167 0.07657909 0.01176471 0.01360544 0.01897533\n",
      " 0.09862571]\n"
     ]
    }
   ],
   "source": [
    "print(precision)\n",
    "print(recall)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Animation': 1.0, 'Drama': 0.5242214532871973, 'Comedy': 0.5, 'Horror': 0.25477707006369427, 'Science Fiction': 0.23125}\n",
      "{'War': 0.7172774869109948, 'Thriller': 0.3886300093196645, 'Action': 0.3769574944071588, 'TV Movie': 0.32620320855614976, 'Adventure': 0.25}\n",
      "{'Thriller': 0.2787433155080214, 'Action': 0.25873320537428024, 'Science Fiction': 0.2374331550802139, 'Romance': 0.22198505869797228, 'Adventure': 0.20311070448307408}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "p = dict(Counter(precision_map).most_common(5))\n",
    "print(p)\n",
    "\n",
    "r = dict(Counter(recall_map).most_common(5))\n",
    "print(r)\n",
    "\n",
    "f1 = dict(Counter(f1_score_map).most_common(5))\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testData(model, dataloader, criterion, test_data, device):\n",
    "    print('Testing')\n",
    "    counter = 0\n",
    "    test_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(test_data)/dataloader.batch_size)):\n",
    "            counter += 1\n",
    "            data, target = data['image'].to(device), data['label'].to(device)\n",
    "            outputs = model(data)\n",
    "            # apply sigmoid activation to get all the outputs between 0 and 1\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            test_running_loss += loss.item()\n",
    "        \n",
    "        test_loss = test_running_loss / counter\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6417/6417 [01:08<00:00, 93.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125740955788825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = testData(model, test_loader, criterion, test_data, device)\n",
    "print(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
